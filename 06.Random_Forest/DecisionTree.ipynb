{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxLsWy9UN5Rx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Node class:** This class represents nodes in the decision tree. Nodes can either be internal nodes (decision nodes) or leaf nodes (terminal nodes). Internal nodes contain information about features and thresholds for splitting, as well as references to their left and right child nodes. Leaf nodes store the predicted value for a subset of data."
      ],
      "metadata": {
        "id": "HwTUyTi7O3zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node():\n",
        "\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, gain=None, value=None):\n",
        "\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.gain = gain\n",
        "        self.value = value"
      ],
      "metadata": {
        "id": "XoIWFPQ7N6_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Class DecisionTree:**\n",
        "\n",
        "- **split_data:** This method splits the dataset into two subsets based on a specified feature and threshold.\n",
        "\n",
        "- **Gini:** This function calculates the Gini coefficient for a given set of labels. It is defined as:\n",
        "  $$G(S) = 1 - \\sum_{i=1}^{n} p_i^2,$$\n",
        "  where \\( p_i \\) is the probability of each class label \\( i \\) in the dataset \\( S \\).\n",
        "\n",
        "- **Information gain:** This function calculates the information gain by finding the difference between the Gini coefficient of the parent node and the weighted sum of the Gini coefficients of its child nodes. It uses the formula:\n",
        "  $$IG(S, A) = G(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} G(S_v),$$\n",
        "  where:\n",
        "  - \\( S \\) is the dataset,\n",
        "  - \\( A \\) is the attribute,\n",
        "  - \\( S_v \\) are subsets of \\( S \\) for each value \\( v \\) of attribute \\( A \\).\n",
        "\n",
        "- **best_split:** This function finds the best split for the dataset by iterating through all features and their unique values to calculate the information gain. It returns the index of the feature, threshold, and two resulting datasets that maximize the information gain.\n",
        "\n",
        "- **calculate_leaf_value:** This function calculates the value for a leaf node. It finds the most common label in the given label set and assigns it as the value of the leaf node.\n",
        "\n",
        "- **build_tree:** This function recursively builds the decision tree by finding the best split at each node based on information gain. It stops recursion when any of the criteria are met: minimum number of samples or maximum depth. It returns the root of the decision tree.\n",
        "\n",
        "- **fit:** This function fits the decision tree to the training data. It constructs the dataset by combining features and labels, then builds the tree using the 'build_tree' function.\n",
        "\n",
        "- **predict:** This function predicts labels for input data samples using the trained decision tree. It iterates through each sample and makes predictions by traversing the tree until reaching a leaf node.\n",
        "\n",
        "- **make_prediction:** This function predicts the label for a single input sample by traversing the decision tree until reaching a leaf node. It returns the label assigned to the leaf node.\n"
      ],
      "metadata": {
        "id": "XwyzLFSGO6H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree():\n",
        "\n",
        "    def __init__(self, min_samples=2, max_depth=None):\n",
        "\n",
        "        self.min_samples = min_samples\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def split_data(self, dataset, feature, threshold):\n",
        "\n",
        "        left_dataset = []\n",
        "        right_dataset = []\n",
        "\n",
        "        for row in dataset:\n",
        "            if row[feature] <= threshold:\n",
        "                left_dataset.append(row)\n",
        "            else:\n",
        "                right_dataset.append(row)\n",
        "\n",
        "        left_dataset = np.array(left_dataset)\n",
        "        right_dataset = np.array(right_dataset)\n",
        "        return left_dataset, right_dataset\n",
        "\n",
        "    def gini(self, y):\n",
        "        gini = 1\n",
        "        labels = np.unique(y)\n",
        "        for label in labels:\n",
        "            label_examples = y[y == label]\n",
        "            pl = len(label_examples) / len(y)\n",
        "            gini -= pl**2\n",
        "        return gini\n",
        "\n",
        "\n",
        "    def information_gain(self, parent, left, right):\n",
        "        information_gain = 0\n",
        "        parent_gini = self.gini(parent)\n",
        "        weight_left = len(left) / len(parent)\n",
        "        weight_right = len(right) / len(parent)\n",
        "        gini_left, gini_right = self.gini(left), self.gini(right)\n",
        "        weighted_gini = weight_left * gini_left + weight_right * gini_right\n",
        "        information_gain = parent_gini - weighted_gini\n",
        "        return information_gain\n",
        "\n",
        "\n",
        "    def best_split(self, dataset, num_samples, num_features):\n",
        "\n",
        "        best_split = {'gain': -1, 'feature': None, 'threshold': None}\n",
        "\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "\n",
        "            if isinstance(feature_values[0], float):\n",
        "                thresholds = np.percentile(feature_values, np.linspace(0, 100, 100))\n",
        "            else:\n",
        "                thresholds = np.unique(feature_values)\n",
        "\n",
        "            for threshold in thresholds:\n",
        "                left_dataset, right_dataset = self.split_data(dataset, feature_index, threshold)\n",
        "                if len(left_dataset) and len(right_dataset):\n",
        "                    y, left_y, right_y = dataset[:, -1], left_dataset[:, -1], right_dataset[:, -1]\n",
        "                    information_gain = self.information_gain(y, left_y, right_y)\n",
        "                    if information_gain > best_split[\"gain\"]:\n",
        "                        best_split[\"feature\"] = feature_index\n",
        "                        best_split[\"threshold\"] = threshold\n",
        "                        best_split[\"left_dataset\"] = left_dataset\n",
        "                        best_split[\"right_dataset\"] = right_dataset\n",
        "                        best_split[\"gain\"] = information_gain\n",
        "        return best_split\n",
        "\n",
        "\n",
        "    def calculate_leaf_value(self, y):\n",
        "\n",
        "        y = list(y)\n",
        "        most_occuring_value = max(y, key=y.count)\n",
        "        return most_occuring_value\n",
        "\n",
        "    def build_tree(self, dataset, current_depth=0):\n",
        "\n",
        "        X, y = dataset[:, :-1], dataset[:, -1]\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        if n_samples >= self.min_samples and (self.max_depth is None or current_depth < self.max_depth):\n",
        "            best_split = self.best_split(dataset, n_samples, n_features)\n",
        "            if best_split[\"gain\"] > 0:\n",
        "                left_dataset = best_split.get(\"left_dataset\", None)\n",
        "                right_dataset = best_split.get(\"right_dataset\", None)\n",
        "\n",
        "                if left_dataset is not None and right_dataset is not None:\n",
        "                    left_node = self.build_tree(left_dataset, current_depth + 1)\n",
        "                    right_node = self.build_tree(right_dataset, current_depth + 1)\n",
        "                    return Node(best_split[\"feature\"], best_split[\"threshold\"],\n",
        "                                left_node, right_node, best_split[\"gain\"])\n",
        "\n",
        "        leaf_value = self.calculate_leaf_value(y)\n",
        "        return Node(value=leaf_value)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        dataset = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            prediction = self.make_prediction(x, self.root)\n",
        "            predictions.append(prediction)\n",
        "        np.array(predictions)\n",
        "        return predictions\n",
        "\n",
        "    def make_prediction(self, x, node):\n",
        "\n",
        "        if node.value != None:\n",
        "            return node.value\n",
        "        else:\n",
        "            feature = x[node.feature]\n",
        "            if feature <= node.threshold:\n",
        "                return self.make_prediction(x, node.left)\n",
        "            else:\n",
        "                return self.make_prediction(x, node.right)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            prediction = self.make_prediction(x, self.root)\n",
        "            proba = [1 - prediction, prediction]\n",
        "            predictions.append(proba)\n",
        "        return np.array(predictions)"
      ],
      "metadata": {
        "id": "1su6nvq0N8WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tree_plot(node, depth=0, xmin=-2, xmax=2):\n",
        "    if node is None:\n",
        "        return\n",
        "\n",
        "    if node.feature is not None:\n",
        "        x_center = (xmin + xmax) / 2\n",
        "        y_center = depth\n",
        "\n",
        "        x_left = xmin if node.left is None else (xmin + x_center) / 2\n",
        "        x_right = xmax if node.right is None else (xmax + x_center) / 2\n",
        "\n",
        "        offset = 0.3\n",
        "        threshold_rounded = round(node.threshold, 3)\n",
        "        plt.text(x_center, y_center, f\"Feature {node.feature} \\n <=  {threshold_rounded}\", ha='center', va='center',\n",
        "                 bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.2'))\n",
        "\n",
        "        if node.left is not None:\n",
        "            plt.arrow(x_center, y_center, x_left - x_center, -0.8, head_width=0.1, head_length=0.1, fc='black', ec='black')\n",
        "            plt.text(x_left, y_center - 1, f\"class:\\n{node.left.value}\", ha='center', va='center')\n",
        "            tree_plot(node.left, depth - 1, xmin, x_center)\n",
        "\n",
        "        if node.right is not None:\n",
        "            plt.arrow(x_center, y_center, x_right - x_center, -0.8, head_width=0.1, head_length=0.1, fc='black', ec='black')\n",
        "            plt.text(x_right, y_center - 1, f\"class:\\n{node.right.value}\", ha='center', va='center')\n",
        "            tree_plot(node.right, depth - 1, x_center, xmax)"
      ],
      "metadata": {
        "id": "71lkxj6xZzfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}