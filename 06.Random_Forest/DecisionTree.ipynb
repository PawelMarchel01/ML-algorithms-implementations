{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxLsWy9UN5Rx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Node class:** Ta klasa reprezentuje węzły w drzewie decyzyjnym. Węzły mogą być węzłami wewnętrznymi (węzłami decyzyjnymi) lub liśćmi (węzłami końcowymi). Węzły wewnętrzne zawierają informacje o cechach i progach podziału, a także odwołania do swoich lewego i prawego dziecka. Liście przechowują przewidywaną wartość dla podzbioru danych."
      ],
      "metadata": {
        "id": "HwTUyTi7O3zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node():\n",
        "\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, gain=None, value=None):\n",
        "\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.gain = gain\n",
        "        self.value = value"
      ],
      "metadata": {
        "id": "XoIWFPQ7N6_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Klasa DecisionTree:**\n",
        "\n",
        "- **split_data:** Ta metoda dzieli zbiór danych na dwa podzbiory na podstawie określonej cechy i progu.\n",
        "\n",
        "- **Gini:** Ta funkcja oblicza nieczystość Gini dla danego zestawu etykiet. Jest ona zdefiniowana wzorem:\n",
        "$$G(S) = 1 - \\sum_{i=1}^{n} p_i^2,$$\n",
        "\n",
        "  gdzie $p_i$ to prawdopodobieństwo wystąpienia każdej etykiety klasy $i$ w zbiorze danych $S$.\n",
        "\n",
        "- **Information gain:** Ta funkcja oblicza zysk informacyjny poprzez znalezienie różnicy między nieczystością Gini węzła rodzica a ważoną sumą nieczystości Gini jego węzłów potomnych. Używa wzoru:\n",
        "  $$IG(S, A) = G(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} G(S_v),$$\n",
        "  gdzie:\n",
        "  - $S$ to zbiór danych,\n",
        "  - $A$ to atrybut,\n",
        "  - $S_v$ to podzbiory $S$ dla każdej wartości $v$ atrybutu $A$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- **best_split:** Ta funkcja znajduje najlepszy podział dla zbioru danych, iterując przez wszystkie cechy i ich unikalne wartości w celu obliczenia zysku informacyjnego. Zwraca indeks cechy, próg i dwa rezultujące zbiory danych, które maksymalizują zysk informacyjny.\n",
        "\n",
        "- **calculate_leaf_value:** Ta funkcja oblicza wartość dla węzła liścia. Znajduje najczęściej występującą etykietę w danym zbiorze etykiet i przypisuje ją jako wartość węzła liścia.\n",
        "\n",
        "- **build_tree:** Ta funkcja rekurencyjnie buduje drzewo decyzyjne, znajdując najlepszy podział w każdym węźle na podstawie zysku informacyjnego. Przerywa rekursję, gdy spełniony zostanie którykolwiek z kryteriów: minimalna liczba próbek lub maksymalna głębokość. Zwraca korzeń drzewa decyzyjnego.\n",
        "\n",
        "- **fit:** Ta funkcja dopasowuje drzewo decyzyjne do danych treningowych. Konstruuje zestaw danych poprzez połączenie cech i etykiet, a następnie buduje drzewo za pomocą funkcji 'build_tree'.\n",
        "\n",
        "- **predict:** Ta funkcja przewiduje etykiety dla próbek danych wejściowych za pomocą wytrenowanego drzewa decyzyjnego. Iteruje przez każdą próbkę i dokonuje predykcji, przechodząc przez drzewo aż do osiągnięcia węzła liścia.\n",
        "\n",
        "- **make_prediction:** Ta funkcja przewiduje etykietę dla pojedynczej próbki wejściowej, przechodząc przez drzewo decyzyjne aż do osiągnięcia węzła liścia. Zwraca etykietę przypisaną do węzła liścia.\n"
      ],
      "metadata": {
        "id": "XwyzLFSGO6H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree():\n",
        "\n",
        "    def __init__(self, min_samples=2, max_depth=None):\n",
        "\n",
        "        self.min_samples = min_samples\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def split_data(self, dataset, feature, threshold):\n",
        "\n",
        "        left_dataset = []\n",
        "        right_dataset = []\n",
        "\n",
        "        for row in dataset:\n",
        "            if row[feature] <= threshold:\n",
        "                left_dataset.append(row)\n",
        "            else:\n",
        "                right_dataset.append(row)\n",
        "\n",
        "        left_dataset = np.array(left_dataset)\n",
        "        right_dataset = np.array(right_dataset)\n",
        "        return left_dataset, right_dataset\n",
        "\n",
        "    def gini(self, y):\n",
        "        gini = 1\n",
        "        labels = np.unique(y)\n",
        "        for label in labels:\n",
        "            label_examples = y[y == label]\n",
        "            pl = len(label_examples) / len(y)\n",
        "            gini -= pl**2\n",
        "        return gini\n",
        "\n",
        "\n",
        "    def information_gain(self, parent, left, right):\n",
        "        information_gain = 0\n",
        "        parent_gini = self.gini(parent)\n",
        "        weight_left = len(left) / len(parent)\n",
        "        weight_right = len(right) / len(parent)\n",
        "        gini_left, gini_right = self.gini(left), self.gini(right)\n",
        "        weighted_gini = weight_left * gini_left + weight_right * gini_right\n",
        "        information_gain = parent_gini - weighted_gini\n",
        "        return information_gain\n",
        "\n",
        "\n",
        "    def best_split(self, dataset, num_samples, num_features):\n",
        "\n",
        "        best_split = {'gain': -1, 'feature': None, 'threshold': None}\n",
        "\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "\n",
        "            if isinstance(feature_values[0], float):\n",
        "                thresholds = np.percentile(feature_values, np.linspace(0, 100, 100))\n",
        "            else:\n",
        "                thresholds = np.unique(feature_values)\n",
        "\n",
        "            for threshold in thresholds:\n",
        "                left_dataset, right_dataset = self.split_data(dataset, feature_index, threshold)\n",
        "                if len(left_dataset) and len(right_dataset):\n",
        "                    y, left_y, right_y = dataset[:, -1], left_dataset[:, -1], right_dataset[:, -1]\n",
        "                    information_gain = self.information_gain(y, left_y, right_y)\n",
        "                    if information_gain > best_split[\"gain\"]:\n",
        "                        best_split[\"feature\"] = feature_index\n",
        "                        best_split[\"threshold\"] = threshold\n",
        "                        best_split[\"left_dataset\"] = left_dataset\n",
        "                        best_split[\"right_dataset\"] = right_dataset\n",
        "                        best_split[\"gain\"] = information_gain\n",
        "        return best_split\n",
        "\n",
        "\n",
        "    def calculate_leaf_value(self, y):\n",
        "\n",
        "        y = list(y)\n",
        "        most_occuring_value = max(y, key=y.count)\n",
        "        return most_occuring_value\n",
        "\n",
        "    def build_tree(self, dataset, current_depth=0):\n",
        "\n",
        "        X, y = dataset[:, :-1], dataset[:, -1]\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        if n_samples >= self.min_samples and (self.max_depth is None or current_depth < self.max_depth):\n",
        "            best_split = self.best_split(dataset, n_samples, n_features)\n",
        "            if best_split[\"gain\"] > 0:\n",
        "                left_dataset = best_split.get(\"left_dataset\", None)\n",
        "                right_dataset = best_split.get(\"right_dataset\", None)\n",
        "\n",
        "                if left_dataset is not None and right_dataset is not None:\n",
        "                    left_node = self.build_tree(left_dataset, current_depth + 1)\n",
        "                    right_node = self.build_tree(right_dataset, current_depth + 1)\n",
        "                    return Node(best_split[\"feature\"], best_split[\"threshold\"],\n",
        "                                left_node, right_node, best_split[\"gain\"])\n",
        "\n",
        "        leaf_value = self.calculate_leaf_value(y)\n",
        "        return Node(value=leaf_value)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        dataset = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            prediction = self.make_prediction(x, self.root)\n",
        "            predictions.append(prediction)\n",
        "        np.array(predictions)\n",
        "        return predictions\n",
        "\n",
        "    def make_prediction(self, x, node):\n",
        "\n",
        "        if node.value != None:\n",
        "            return node.value\n",
        "        else:\n",
        "            feature = x[node.feature]\n",
        "            if feature <= node.threshold:\n",
        "                return self.make_prediction(x, node.left)\n",
        "            else:\n",
        "                return self.make_prediction(x, node.right)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            prediction = self.make_prediction(x, self.root)\n",
        "            proba = [1 - prediction, prediction]\n",
        "            predictions.append(proba)\n",
        "        return np.array(predictions)"
      ],
      "metadata": {
        "id": "1su6nvq0N8WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tree_plot(node, depth=0, xmin=-2, xmax=2):\n",
        "    if node is None:\n",
        "        return\n",
        "\n",
        "    if node.feature is not None:\n",
        "        x_center = (xmin + xmax) / 2\n",
        "        y_center = depth\n",
        "\n",
        "        x_left = xmin if node.left is None else (xmin + x_center) / 2\n",
        "        x_right = xmax if node.right is None else (xmax + x_center) / 2\n",
        "\n",
        "        offset = 0.3\n",
        "        threshold_rounded = round(node.threshold, 3)\n",
        "        plt.text(x_center, y_center, f\"Feature {node.feature} \\n <=  {threshold_rounded}\", ha='center', va='center',\n",
        "                 bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.2'))\n",
        "\n",
        "        if node.left is not None:\n",
        "            plt.arrow(x_center, y_center, x_left - x_center, -0.8, head_width=0.1, head_length=0.1, fc='black', ec='black')\n",
        "            plt.text(x_left, y_center - 1, f\"class:\\n{node.left.value}\", ha='center', va='center')\n",
        "            tree_plot(node.left, depth - 1, xmin, x_center)\n",
        "\n",
        "        if node.right is not None:\n",
        "            plt.arrow(x_center, y_center, x_right - x_center, -0.8, head_width=0.1, head_length=0.1, fc='black', ec='black')\n",
        "            plt.text(x_right, y_center - 1, f\"class:\\n{node.right.value}\", ha='center', va='center')\n",
        "            tree_plot(node.right, depth - 1, x_center, xmax)"
      ],
      "metadata": {
        "id": "71lkxj6xZzfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}